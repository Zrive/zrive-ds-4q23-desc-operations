{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase1.- Formar BBDD\n",
    "\n",
    "## Wikipedia\n",
    "Vamos a probar a construir la descripcion mediante entradas de wikipedia. El punts fuerte de este metodo es que, en caso de encontrar un articulo de la empresa buscada, la informacion será objetiva, facil de obtener y de hacer un resumen. \n",
    "\n",
    "Buscaremos los articulos en ingles. Hay articulos que todavia no se han traducido y cabe la posibilidad que nuestra empresa (si es muy  nicho) tenga un articulo en su idioma nativo y no en EN. Adjunto dos links, en el primero hay articulos en cola de ser traducidos y en el segundo es una herramienta que encuentra atributos dentro de un articulo que no son en ingles (este te redirige a la BBDD de 'entities' de wikidata) (simplemente por si se decide explorarlos explorarlos):\n",
    "\n",
    "- https://not-in-the-other-language.toolforge.org/?lang1=de&proj1=wiki&lang2=en&proj2=wiki&cat=&depth=9&limit=100&starts_with=&start=100&targets=wikidata&doit=1\n",
    "\n",
    "- https://not-in-the-other-language.toolforge.org/?lang1=de&proj1=wiki&lang2=en&proj2=wiki&cat=&depth=9&limit=100&starts_with=&start=100&targets=wikidata&doit=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos acceder de distinatas formas a la API de wikipedia (wikimedia). Con la URL o con la API envualta en la libreria *wikipedia*. Hay dos versiones de la AP disponibles, la --v 1.4.0 y la --v 0.6.0. Primero importaremos el POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Company name                          Website  \\\n",
      "0                    Oakland University             https://oakland.edu/   \n",
      "1            TomTom North America, Inc.  https://www.tomtom.com/company/   \n",
      "2                                    3m              https://www.3m.com/   \n",
      "3                       DIVCON Controls      https://divconcontrols.com/   \n",
      "4  San Francisco Elevator Services Inc.              https://sfelev.com/   \n",
      "5      North Jersey Inspection Services                              NaN   \n",
      "6                         R Recruitment                              NaN   \n",
      "7                        Consume 4 Less                              NaN   \n",
      "8       SK and Company Accountants Ltd.                              NaN   \n",
      "9                        Themathsurgery       http://themathsurgery.com/   \n",
      "\n",
      "                                         Description  \n",
      "0  Oakland University harnesses the transformativ...  \n",
      "1  If you ever found yourself in a car in the nou...  \n",
      "2  3M touches virtually every part of your life. ...  \n",
      "3  At Divcon Controls, our mission is to provide ...  \n",
      "4  San Francisco Elevator Services, Inc., is an i...  \n",
      "5                                                NaN  \n",
      "6  Hire Your Next Candidate with R Recruitment Ag...  \n",
      "7                                                NaN  \n",
      "8  SK & Co is a Registered Accounting Services fi...  \n",
      "9  We are passionate about delivering high qualit...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ruta_csv = '../data/data.csv'\n",
    "df = pd.read_csv(ruta_csv, sep=',')\n",
    "print(df.head(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer problmea que encontramos es que en las busquedas de articlos en la API de wikipedia podremos obtener diversos resultados, de contenido completamente distinto. Sobre los titulos de los articulos podemos leer la info (se ve que se ordenan segun 'experienced editors'):\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Wikipedia:Article_titles/Criteria_order\n",
    "\n",
    "Podemos ordenar las paginas con el parametro srsort de 'generator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zara  - Word count:  283\n",
      "Zara Hatke Zara Bachke  - Word count:  1736\n",
      "Zara (retailer)  - Word count:  4209\n",
      "Zara Larsson  - Word count:  5826\n",
      "Zara Tindall  - Word count:  3068\n",
      "Zara McDermott  - Word count:  1471\n",
      "Zara (name)  - Word count:  646\n",
      "Zara Larsson discography  - Word count:  3268\n",
      "Zara Home  - Word count:  124\n",
      "Zara, Turkey  - Word count:  166\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "query = 'zara'\n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "            'action':'query',\n",
    "            'format':'json',\n",
    "            'list':'search',\n",
    "            'utf8':1,\n",
    "            'srsearch':query\n",
    "        }\n",
    "\n",
    "data = requests.get(url, params=params).json() \n",
    "for i in data['query']['search']:\n",
    "    print(i['title'], ' - Word count: ', i['wordcount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la anterior querry buscamos 'zara' en el buscador de la API y aparecen todos los articulos diferentes. A nosotros nos interesa 'Zara (retailer)' pero a priori no podemos identificar sobre la lista de resultados cual es el que nos interesa, ya que en el .csv POC encontramos universidades, tiendas, ... y demás casuísticas que no podemos controlar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un walk around seria filtrar los articulos resultado por algunas categorias hardcodeadas. La api de wikipedia no permite hacer busquedas con una categoria como filtro y además wikimedia ha establecido toda una jerarquia de categorias, por lo que puede que la empresa a buscar esté en la categoria 'universidades de UK' y no en la categoria 'universidades' (pese a estar 'universidades de UK' dentro de la categoria de 'universidades', claro) \n",
    "\n",
    "Si que se podrian obtener todos los articulos existentes de la categoria (p.ej) 'Bussiness'. De nuevo, no tenemos total certeza que lo que se busquen sean negocios de esa categoria y tendriamos muchas instancias no utilizadas. \n",
    "\n",
    "El meta-parametro 'generator' determina que paginas queremos mostrar. Una idea: podria cruzarse la localizacion (coordenadas) de la empresa y el paremetro de generator: geosearch. Hay que explorarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de un full search (texto de todas las entradas antes de la pruimera seccion, lo que se considera el Resumen de wikipedia) de 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titulo: Ball python :\n",
      " The ball python (Python regius), also called the royal python, is a python species native to West and Central Africa, where it lives in grasslands, shrublands and open forests. This nonvenomous constrictor is the smallest of the African pythons, growing to a maximum length of 182 cm (72 in). The name \"ball python\" refers to its tendency to curl into a ball when stressed or frightened.\n",
      "\n",
      "\n",
      "Titulo: Burmese python :\n",
      " The Burmese python (Python bivittatus) is one of the largest species of snakes. It is native to a large area of Southeast Asia and is listed as Vulnerable on the IUCN Red List. Until 2009, it was considered a subspecies of the Indian python, but is now recognized as a distinct species. It is an invasive species in Florida as a result of the pet trade.\n",
      "\n",
      "\n",
      "Titulo: Colt Python :\n",
      " The Colt Python is a double action revolver chambered for the .357 Magnum cartridge. It was first introduced in 1955 by the Colt's Manufacturing Company. Pythons have a reputation for accuracy, smooth trigger pull, and a tight cylinder lock-up. Pythons, built on Colt's large I-frame, are similar in size and function to the Colt Trooper and  Colt Lawman revolvers.The Colt Python is intended for the premium revolver market segment. Official Colt historian R.L. Wilson described the Colt Python as \"the Rolls-Royce of Colt revolvers\", and firearms historian Ian V. Hogg referred to it as the \"best revolver in the world\".\n",
      "Some firearm collectors and writers such as Jeff Cooper and Ian V. Hogg have described the Python as \"the finest production revolver ever made\".\n",
      "\n",
      "\n",
      "Titulo: Monty Python :\n",
      " Monty Python (also collectively known as the Pythons) were a British comedy troupe formed in 1969 consisting of Graham Chapman, John Cleese, Terry Gilliam, Eric Idle, Terry Jones, and Michael Palin. The group came to prominence for the sketch comedy series Monty Python's Flying Circus, which aired on the BBC from 1969 to 1974. Their work then developed into a larger collection that included live shows, films, albums, books, and musicals; their influence on comedy has been compared to the Beatles' influence on music. Their sketch show has been called \"an important moment in the evolution of television comedy\".Monty Python's Flying Circus was loosely structured as a sketch show, but its innovative stream-of-consciousness approach and Gilliam's animation skills pushed the boundaries of what was acceptable in style and content. The Pythons had creative control which allowed them to experiment with form and content, discarding rules of television comedy. They followed their television work by making  the films Monty Python and the Holy Grail (1975), Life of Brian (1979), and The Meaning of Life (1983). Their influence on British comedy has been apparent for years, while it has coloured the work of the early editions of Saturday Night Live through to absurdist trends in television comedy.\n",
      "At the 41st British Academy Film Awards in 1988, Monty Python received the BAFTA Award for Outstanding British Contribution to Cinema. In 1998, they were awarded the AFI Star Award by the American Film Institute. Holy Grail and Life of Brian are frequently ranked on lists of the greatest comedy films. A 2005 poll asked more than 300 comedians, comedy writers, producers, and directors to name the greatest comedians of all time, and half of Monty Python's members made the top 50.\n",
      "\n",
      "\n",
      "Titulo: Python :\n",
      " Python may refer to:\n",
      "\n",
      "\n",
      "Titulo: Python (codename) :\n",
      " Python was a Cold War contingency plan of the British Government for the continuity of government in the event of nuclear war.\n",
      "Titulo: Python (missile) :\n",
      " The Rafael Python is a family of air-to-air missiles (AAMs) built by the Israeli weapons manufacturer Rafael Advanced Defense Systems, formerly RAFAEL Armament Development Authority. Originally starting with the Shafrir (Hebrew: שפריר, loosely translated as a dome, or a protective cloak – the Israeli military considers itself mostly defensive, but also similar sounding to Dragonfly, a male form of inflection for Damselfly (שפירית)) series, the Shafrir-1 missile was developed in 1959, followed by the Shafrir-2 in early 1970s. Subsequently, the missiles were given the western name of \"Python\" by the parent company for export purposes, starting with the Python-3 in 1978. Since then, it has been further developed and evolved into the Python-4, Python-5, Derby and also, the SPYDER, an advanced ground-based air-defence system. Currently, the missiles are in service with the armed forces of over fifteen countries from around the world.\n",
      "Titulo: Python (programming language) :\n",
      " Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.Python consistently ranks as one of the most popular programming languages.\n",
      "Titulo: Reticulated python :\n",
      " The reticulated python (Malayopython reticulatus) is a python species native to South and Southeast Asia. It is the world's longest snake, and the third heaviest after the green anaconda and Burmese python. It is listed as least concern on the IUCN Red List because of its wide distribution. In several countries in its range, it is hunted for its skin, for use in traditional medicine, and for sale as pets. Due to this, reticulated pythons are one of the most economically important reptiles worldwide.It is an excellent swimmer, has been reported far out at sea, and has colonized many small islands within its range.\n",
      "Like all pythons, it is a non-venomous constrictor. In very rare cases, adult humans have been killed (and in at least two reported cases, eaten) by reticulated pythons.\n",
      "Titulo: Setuptools :\n",
      " setuptools is a package development process library designed to facilitate packaging Python projects by enhancing the Python standard library distutils (distribution utilities). It includes:\n",
      "\n",
      "Python package and module definitions\n",
      "Distribution package metadata\n",
      "Test hooks\n",
      "Project installation\n",
      "Platform-specific details\n",
      "Python 3 support\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "subject = 'Python'\n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "        'origin':'*',\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'prop': 'extracts',\n",
    "        'exintro': True,\n",
    "        'explaintext': True,\n",
    "        'generator': \"search\",\n",
    "        'gsrsearch': subject,\n",
    "        'gsrwhat':'text',\n",
    "        'gsrsort': 'relevance'\n",
    "    }\n",
    " \n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "for i in data['query']['pages'].values():\n",
    "    print('Titulo:',i['title'],':\\n', i['extract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full text de una pagina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.[31]\n",
      "Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.[32][33]\n",
      "Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0.[34] Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.[35]\n",
      "Python consistently ranks as one of the most popular programming languages.[36][37][38][39]\n",
      "Python was conceived in the late 1980s[40] by Guido van Rossum at Centrum Wiskunde & \n",
      "Text length:  26570\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    " \n",
    "subject = 'Python (programming language)'\n",
    " \n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "            'action': 'parse',\n",
    "            'page': subject,\n",
    "            'format': 'json',\n",
    "            'prop':'text',\n",
    "            'redirects':''\n",
    "        }\n",
    " \n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    " \n",
    "raw_html = data['parse']['text']['*']\n",
    "soup = BeautifulSoup(raw_html,'html.parser')\n",
    "soup.find_all('p')\n",
    "text = ''\n",
    " \n",
    "for p in soup.find_all('p'):\n",
    "    text += p.text\n",
    " \n",
    "print(text[:1000])\n",
    "print('Text length: ', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 'badvalue', 'info': 'Unrecognized value for parameter \"action\": wbsearchentities.', '*': 'See https://en.wikipedia.org/w/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &lt;https://lists.wikimedia.org/postorius/lists/mediawiki-api-announce.lists.wikimedia.org/&gt; for notice of API deprecations and breaking changes.'}, 'servedby': 'mw-api-ext.eqiad.main-675759d54b-hsss7'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "subject = 'Python'\n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "query = \"wikipedia\"\n",
    "params = {\n",
    "    'action': 'wbsearchentities',\n",
    "    'format': 'json',\n",
    "    'language': 'en',\n",
    "    'search': query\n",
    "    }\n",
    " \n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "print(data)\n",
    "# page = next(iter(data['query']['pages'].values()))\n",
    "# print(page['extract'][:73])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priorio solo querríamos obtener el summary de una pagina o su texto al completo. Con las siguientes funciones podemos obtener texto por las secciones definidas de una pagina "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "def get_sections(\n",
    "     section: wikipediaapi.WikipediaPageSection,\n",
    "     parent_title: list[str],\n",
    "     sections_to_ignore: set[str]\n",
    "     ) -> list[tuple[list[str],str]]:\n",
    "    \n",
    "     \"\"\"Gather sections and subsections data.\"\"\"\n",
    "    \n",
    "     sect_title = section.title \n",
    "     title = parent_title\n",
    "     title.extend([sect_title])\n",
    "     results = []\n",
    "     \n",
    "     if sect_title not in sections_to_ignore:\n",
    "       sect_text = section.text \n",
    "       string_section = ( title , sect_text)\n",
    "       results.extend([string_section])\n",
    "  \n",
    "       if len(section.sections)>1:\n",
    "         for subsection in section.sections:\n",
    "           get_sections(subsection, title, sections_to_ignore) \n",
    "\n",
    "     return results\n",
    "\n",
    "def get_pages (\n",
    "     page: wikipediaapi.WikipediaPage,\n",
    "     sections_to_ignore: set[str]\n",
    "     )-> list[tuple[list[str],str]]:\n",
    "\n",
    "     \"\"\"Gather the page information: title and summary, and then go deep in sections information.\"\"\"\n",
    "   \n",
    "     parent_title = page.title\n",
    "     print(f\"parent_title = {parent_title} \")\n",
    "\n",
    "     summary = page.summary\n",
    "     string_parent = ([parent_title], summary)\n",
    "     results=[string_parent]\n",
    "     \n",
    "     if len(page.sections) > 0:\n",
    "       for section in page.sections:\n",
    "         results.extend(get_sections(section,[parent_title], sections_to_ignore))\n",
    "    \n",
    "     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  {'2022 FIFA World Cup': 2022 FIFA World Cup (id: ??, ns: 0), '2015 FIFA corruption case': 2015 FIFA corruption case (id: ??, ns: 0), '2022 FIFA World Cup opening ceremony': 2022 FIFA World Cup opening ceremony (id: ??, ns: 0), 'Adidas Al Rihla': Adidas Al Rihla (id: ??, ns: 0), 'Allegations of corruption and bribery related to the 2022 FIFA World Cup': Allegations of corruption and bribery related to the 2022 FIFA World Cup (id: ??, ns: 0), 'Battle of Lusail': Battle of Lusail (id: ??, ns: 0), '2018 and 2022 FIFA World Cup bids': 2018 and 2022 FIFA World Cup bids (id: ??, ns: 0), '2022 FIFA World Cup broadcasting rights': 2022 FIFA World Cup broadcasting rights (id: ??, ns: 0), \"Criticisms of Qatar's suitability to host the 2022 FIFA World Cup\": Criticisms of Qatar's suitability to host the 2022 FIFA World Cup (id: ??, ns: 0), 'List of 2022 FIFA World Cup controversies': List of 2022 FIFA World Cup controversies (id: ??, ns: 0), 'Dreamers (Jungkook song)': Dreamers (Jungkook song) (id: ??, ns: 0), 'FIFA World Cup Qatar 2022 Official Soundtrack': FIFA World Cup Qatar 2022 Official Soundtrack (id: ??, ns: 0), '2022 FIFA World Cup final': 2022 FIFA World Cup final (id: ??, ns: 0), 'Garcia Report': Garcia Report (id: ??, ns: 0), '2022 FIFA World Cup Group A': 2022 FIFA World Cup Group A (id: ??, ns: 0), '2022 FIFA World Cup Group B': 2022 FIFA World Cup Group B (id: ??, ns: 0), '2022 FIFA World Cup Group C': 2022 FIFA World Cup Group C (id: ??, ns: 0), '2022 FIFA World Cup Group D': 2022 FIFA World Cup Group D (id: ??, ns: 0), '2022 FIFA World Cup Group E': 2022 FIFA World Cup Group E (id: ??, ns: 0), '2022 FIFA World Cup Group F': 2022 FIFA World Cup Group F (id: ??, ns: 0), '2022 FIFA World Cup Group G': 2022 FIFA World Cup Group G (id: ??, ns: 0), '2022 FIFA World Cup Group H': 2022 FIFA World Cup Group H (id: ??, ns: 0), 'Hayya Hayya (Better Together)': Hayya Hayya (Better Together) (id: ??, ns: 0), '2022 FIFA World Cup knockout stage': 2022 FIFA World Cup knockout stage (id: ??, ns: 0), \"La'eeb\": La'eeb (id: ??, ns: 0), 'Ghanim Al-Muftah': Ghanim Al-Muftah (id: ??, ns: 0), '2022 FIFA World Cup officials': 2022 FIFA World Cup officials (id: ??, ns: 0), '2022 FIFA World Cup qualification': 2022 FIFA World Cup qualification (id: ??, ns: 0), '2022 FIFA World Cup seeding': 2022 FIFA World Cup seeding (id: ??, ns: 0), '2022 FIFA World Cup squads': 2022 FIFA World Cup squads (id: ??, ns: 0), 'Hassan Al-Thawadi': Hassan Al-Thawadi (id: ??, ns: 0), 'Tukoh Taka': Tukoh Taka (id: ??, ns: 0), 'The Workers Cup': The Workers Cup (id: ??, ns: 0), 'Category:2022 FIFA World Cup bids': Category:2022 FIFA World Cup bids (id: ??, ns: 14), 'Category:2022 FIFA World Cup controversies': Category:2022 FIFA World Cup controversies (id: ??, ns: 14), 'Category:Countries at the 2022 FIFA World Cup': Category:Countries at the 2022 FIFA World Cup (id: ??, ns: 14), 'Category:2022 FIFA World Cup managers': Category:2022 FIFA World Cup managers (id: ??, ns: 14), 'Category:2022 FIFA World Cup players': Category:2022 FIFA World Cup players (id: ??, ns: 14), 'Category:2022 FIFA World Cup qualification': Category:2022 FIFA World Cup qualification (id: ??, ns: 14), 'Category:2022 FIFA World Cup referees': Category:2022 FIFA World Cup referees (id: ??, ns: 14), 'Category:2022 FIFA World Cup stadiums': Category:2022 FIFA World Cup stadiums (id: ??, ns: 14), 'Category:2022 FIFA World Cup templates': Category:2022 FIFA World Cup templates (id: ??, ns: 14), 'File:2022 FIFA World Cup.svg': File:2022 FIFA World Cup.svg (id: ??, ns: 6)}\n",
      "parent_title = 2022 FIFA World Cup \n",
      "parent_title = 2015 FIFA corruption case \n",
      "parent_title = 2022 FIFA World Cup opening ceremony \n",
      "parent_title = Adidas Al Rihla \n",
      "parent_title = Allegations of corruption and bribery related to the 2022 FIFA World Cup \n",
      "parent_title = Battle of Lusail \n",
      "parent_title = 2018 and 2022 FIFA World Cup bids \n",
      "parent_title = 2022 FIFA World Cup broadcasting rights \n",
      "parent_title = Criticisms of Qatar's suitability to host the 2022 FIFA World Cup \n",
      "parent_title = List of 2022 FIFA World Cup controversies \n",
      "parent_title = Dreamers (Jungkook song) \n",
      "parent_title = FIFA World Cup Qatar 2022 Official Soundtrack \n",
      "parent_title = 2022 FIFA World Cup final \n",
      "parent_title = Garcia Report \n",
      "parent_title = 2022 FIFA World Cup Group A \n",
      "parent_title = 2022 FIFA World Cup Group B \n",
      "parent_title = 2022 FIFA World Cup Group C \n",
      "parent_title = 2022 FIFA World Cup Group D \n",
      "parent_title = 2022 FIFA World Cup Group E \n",
      "parent_title = 2022 FIFA World Cup Group F \n",
      "parent_title = 2022 FIFA World Cup Group G \n",
      "parent_title = 2022 FIFA World Cup Group H \n",
      "parent_title = Hayya Hayya (Better Together) \n",
      "parent_title = 2022 FIFA World Cup knockout stage \n",
      "parent_title = La'eeb \n",
      "parent_title = Ghanim Al-Muftah \n",
      "parent_title = 2022 FIFA World Cup officials \n",
      "parent_title = 2022 FIFA World Cup qualification \n",
      "parent_title = 2022 FIFA World Cup seeding \n",
      "parent_title = 2022 FIFA World Cup squads \n",
      "parent_title = Hassan Al-Thawadi \n",
      "parent_title = Tukoh Taka \n",
      "parent_title = The Workers Cup \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['2022 FIFA World Cup'],\n",
       "  \"The 2022 FIFA World Cup was the 22nd FIFA World Cup, the world championship for national football teams organized by FIFA. It took place in Qatar from 20 November to 18 December 2022, after the country was awarded the hosting rights in 2010. It was the first World Cup to be held in the Arab world and Muslim world, and the second held entirely in Asia after the 2002 tournament in South Korea and Japan.This tournament was the last with 32 participating teams, with the number of teams being increased to 48 for the 2026 edition. To avoid the extremes of Qatar's hot climate, the event was held during November and December instead of in the traditional months of May, June, or July. It was held over a reduced time frame of 29 days with 64 matches played in eight venues across five cities. Qatar entered the event—their first World Cup—automatically as the host's national team, alongside 31 teams determined by the qualification process.\\nArgentina were crowned the champions after winning the final against the title holder France 4–2 on penalties following a 3–3 draw after extra time. It was Argentina's third title and their first since 1986, as well as being the first nation from outside of Europe to win the tournament since 2002. French player Kylian Mbappé became the first player to score a hat-trick in a World Cup final since Geoff Hurst in the 1966 final and won the Golden Boot as he scored the most goals (eight) during the tournament. Argentine captain Lionel Messi was voted the tournament's best player, winning the Golden Ball. The tournament has been considered exceptionally poetic as the capstone of his career, for some commentators fulfilling a previously unmet criterion to be regarded the greatest player of all time. Teammates Emiliano Martínez and Enzo Fernández won the Golden Glove, awarded to the tournament's best goalkeeper; and the Young Player Award, awarded to the tournament's best young player, respectively. With 172 goals, the tournament set a record for the highest number of goals scored in the 32-team format, with every participating team scoring at least one goal.\\nThe choice to host the World Cup in Qatar attracted significant criticism, with concerns raised over the country's treatment of migrant workers, women and members of the LGBT community, as well as Qatar's climate, lack of a strong football culture, scheduling changes, and allegations of bribery for hosting rights and wider FIFA corruption.\"),\n",
       " (['2022 FIFA World Cup', 'Format', 'Schedule', 'Prize money', 'Rule changes'],\n",
       "  'The FIFA World Cup is a professional football tournament held between national football teams, organised by FIFA. The tournament, held every four years, was first played in 1930 in Uruguay, and has been contested by 32 teams since the 1998 event. The tournament was contested with eight round-robin groups followed by a knockout round for 16 teams. The defending champions were France, who defeated Croatia 4–2 in the 2018 FIFA World Cup Final. The event was scheduled to take place under a reduced length, from 20 November to 18 December in Qatar. Being held in Qatar, it was the first World Cup tournament to be held in the Arab world. Spectators were not required to follow most COVID-19 pandemic restrictions such as social distancing, wearing masks, and negative tests.'),\n",
       " (['2022 FIFA World Cup', 'Host selection'],\n",
       "  'The bidding procedure to host the 2018 and 2022 FIFA World Cups began in January 2009. National associations had until 2 February 2009 to register interest. Initially, 11 bids were made for the 2018 FIFA World Cup, but Mexico withdrew from proceedings, and Indonesia\\'s bid was rejected by FIFA in February 2010 after the Indonesian Football Association failed to submit a letter of Indonesian government guarantee to support the bid.After UEFA were guaranteed to host the 2018 event, members of UEFA were no longer in contention to host in 2022. There were five bids remaining for the 2022 FIFA World Cup: Australia, Japan, Qatar, South Korea, and the United States.\\nThe 22-member FIFA Executive Committee convened in Zürich, Switzerland, on 2 December 2010 to vote to select the hosts of both tournaments. Two FIFA executive committee members were suspended before the vote in relation to allegations of corruption regarding their votes. The decision to host the 2022 World Cup in Qatar, which was graded as having \"high operational risk\", generated criticism from media commentators. It was criticised by many as being part of the FIFA corruption scandals, which led to the 2015 FIFA corruption case.\\nThe voting patterns were as follows:'),\n",
       " (['2022 FIFA World Cup', 'Venues', 'Stadiums', 'Security'],\n",
       "  \"The first five proposed venues for the World Cup were unveiled at the beginning of March 2010. Qatar intended that the stadiums should reflect its history and culture, and for the designs to meet the following terms of reference: legacy, comfort, accessibility, and sustainability. The stadiums were equipped with cooling systems that aim to reduce temperatures within the stadium by up to 20 °C (36 °F).Their marketing included statements describing the stadiums as zero waste, and the upper tiers of the stadiums will be disassembled after the World Cup and donated to countries with less developed sports infrastructure. Qatar aspired to be compliant and certified by the Global Sustainability Assessment System (GSAS) for all the World Cup stadiums. All of the five stadium projects launched were designed by German architect Albert Speer & Partners. The Al Bayt and Al Wakrah stadiums were the only indoor stadiums of the eight used.\\nIn an April 2013 report by Merrill Lynch, the organisers in Qatar requested that FIFA approve a smaller number of stadiums due to the growing costs. Bloomberg said that Qatar wished to cut the number of venues to eight or nine from the twelve originally planned. By April 2017, FIFA had yet to finalise the number of stadiums Qatar must have readied in five years' time. Qatar's Supreme Committee for Delivery and Legacy (SC) said it expected there would be eight in and near Doha, with the exception of Al Khor.Stadium 974, formerly known as the Ras Abu Aboud Stadium, was the seventh FIFA World Cup 2022 venue to be completed by the SC. Its name comes from the number of shipping containers used in its construction and Qatar's international dialling code. The venue will be dismantled completely after the tournament—this stadium was the first temporary stadium ever used for a FIFA World Cup. All of the other stadiums used except Khalifa International were reduced in capacity by half.\"),\n",
       " (['2022 FIFA World Cup', 'Teams', 'Qualification', 'Squads', 'Draw'], '')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SECTIONS_TO_IGNORE = [\n",
    " \"See also\", \"References\", \"External links\",\n",
    " \"Further reading\", \"Footnotes\", \"Bibliography\",\n",
    " \"Sources\", \"Citations\", \"Literature\",\n",
    " \"Photo gallery\", \"Photos\", \"Gallery\",\n",
    " \"Works cited\", \"Notes\", \"Notes and references\",\n",
    " \"References and sources\", \"References and notes\",\n",
    "]\n",
    "wiki = wikipediaapi.Wikipedia('ExtractBussinesInfo (ramoncormo8@gmial.com)', language='en')\n",
    "CATEGORY_TITLE = \"Category:2022 FIFA World Cup\"\n",
    "\n",
    "# Get the category object for \"2022 FIFA World Cup\"\n",
    "cat = wiki.page(CATEGORY_TITLE)\n",
    "\n",
    "# Print the name of the category\n",
    "print(\"Name: \", cat.categorymembers)\n",
    "# Get the articles included in this category\n",
    "# # if it's an article: wikipediaapi.Namespace.MAIN = 0\n",
    "# # if it's a subcategory: wikipediaapi.Namespace.CATEGORY = 14\n",
    "articles = [w for w in cat.categorymembers.values() if w.ns == wikipediaapi.Namespace.MAIN]\n",
    "\n",
    "wiki_corpus=[]\n",
    "for page in articles:\n",
    "    wiki_corpus.extend(get_pages(page, SECTIONS_TO_IGNORE))\n",
    "\n",
    "wiki_corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para parsear respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He tomado estas decisiones (a priori): Usar el endpoint URL y la libreria wikipedia --v 1.4.0 para el suggest; Si hay mas de una respeusta coger la info de la primera respuesta con un '**WARNING - need to check veracity**' al principio (hay que mirar mas a fondo el parametro gsrsort o alguno de sorting); Si no hay articulos relacionados al input, aplica la funcion suggest de la libreria wikipedia-api y vuelve a probar; Si no hay respuesta devuelve: 'No content'\n",
    "\n",
    "Caveats: hay que definir dos veces los parametros, ya que sino no funciona (una cosa es buscar los titulos y otra es buscar el abstract de un titulo en concreto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "print(wikipedia.suggest(\"qwerqwecq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python may refer to:\n",
      "\n",
      "\n",
      "dict_keys(['46332325'])\n"
     ]
    }
   ],
   "source": [
    "subject = 'Python'\n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "            'action':'query',\n",
    "            'format':'json',\n",
    "            'list':'search',\n",
    "            'utf8':1,\n",
    "            'srsearch':query\n",
    "        }\n",
    " \n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    " \n",
    "page = next(iter(data['query']['pages'].values()))\n",
    "print(page['extract'])\n",
    "print(dict(data['query']['pages']).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchcomplete': '', 'continue': {'gsroffset': 10, 'continue': 'gsroffset||'}, 'warnings': {'extracts': {'*': 'HTML may be malformed and/or unbalanced and may omit inline images. Use at your own risk. Known problems are listed at https://www.mediawiki.org/wiki/Special:MyLanguage/Extension:TextExtracts#Caveats.'}}, 'query': {'pages': {'271890': {'pageid': 271890, 'ns': 0, 'title': 'Ball python', 'index': 4, 'extract': '<p class=\"mw-empty-elt\">\\n\\n\\n</p>\\n<p>The <b>ball python</b> (<i><b>Python regius</b></i>), also called the <b>royal python</b>, is a python species native to West and Central Africa, where it lives in grasslands, shrublands and open forests. This nonvenomous constrictor is the smallest of the African pythons, growing to a maximum length of 182\\xa0cm (72\\xa0in). The name \"ball python\" refers to its tendency to curl into a ball when stressed or frightened.</p>\\n\\n\\n'}, '819149': {'pageid': 819149, 'ns': 0, 'title': 'Burmese python', 'index': 6, 'extract': '<p class=\"mw-empty-elt\">\\n</p>\\n\\n<p class=\"mw-empty-elt\">\\n</p>\\n<p>The <b>Burmese python</b> (<i><b>Python bivittatus</b></i>) is one of the largest species of snakes. It is native to a large area of Southeast Asia and is listed as Vulnerable on the IUCN Red List. Until 2009, it was considered a subspecies of the Indian python, but is now recognized as a distinct species. It is an invasive species in Florida as a result of the pet trade.</p>\\n\\n\\n'}, '639888': {'pageid': 639888, 'ns': 0, 'title': 'Colt Python', 'index': 10, 'extract': '<p class=\"mw-empty-elt\">\\n</p>\\n<p><br>\\nThe <b>Colt Python</b> is a double action revolver chambered for the .357 Magnum cartridge. It was first introduced in 1955 by the Colt\\'s Manufacturing Company. </p><p>Pythons have a reputation for accuracy, smooth trigger pull, and a tight cylinder lock-up. Pythons, built on Colt\\'s large I-frame, are similar in size and function to the Colt Trooper and  Colt Lawman revolvers.</p><p>The Colt Python is intended for the premium revolver market segment. Official Colt historian R.L. Wilson described the Colt Python as \"the Rolls-Royce of Colt revolvers\", and firearms historian Ian V. Hogg referred to it as the \"best revolver in the world\".\\nSome firearm collectors and writers such as Jeff Cooper and Ian V. Hogg have described the Python as \"the finest production revolver ever made\".</p><p><br></p>'}, '18942': {'pageid': 18942, 'ns': 0, 'title': 'Monty Python', 'index': 3, 'extract': '<link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1033289096\">\\n<link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1033289096\">\\n<p class=\"mw-empty-elt\">\\n\\n</p>\\n<p><b>Monty Python</b> (also collectively known as <b>the Pythons</b>) were a British comedy troupe formed in 1969 consisting of Graham Chapman, John Cleese, Terry Gilliam, Eric Idle, Terry Jones, and Michael Palin. The group came to prominence for the sketch comedy series <i>Monty Python\\'s Flying Circus</i>, which aired on the BBC from 1969 to 1974. Their work then developed into a larger collection that included live shows, films, albums, books, and musicals; their influence on comedy has been compared to the Beatles\\' influence on music. Their sketch show has been called \"an important moment in the evolution of television comedy\".</p><p><i>Monty Python\\'s Flying Circus</i> was loosely structured as a sketch show, but its innovative stream-of-consciousness approach and Gilliam\\'s animation skills pushed the boundaries of what was acceptable in style and content. The Pythons had creative control which allowed them to experiment with form and content, discarding rules of television comedy. They followed their television work by making  the films <i>Monty Python and the Holy Grail</i> (1975), <i>Life of Brian</i> (1979), and <i>The Meaning of Life</i> (1983). Their influence on British comedy has been apparent for years, while it has coloured the work of the early editions of <i>Saturday Night Live</i> through to absurdist trends in television comedy.\\n</p><p>At the 41st British Academy Film Awards in 1988, Monty Python received the BAFTA Award for Outstanding British Contribution to Cinema. In 1998, they were awarded the AFI Star Award by the American Film Institute. <i>Holy Grail</i> and <i>Life of Brian</i> are frequently ranked on lists of the greatest comedy films. A 2005 poll asked more than 300 comedians, comedy writers, producers, and directors to name the greatest comedians of all time, and half of Monty Python\\'s members made the top 50.</p>\\n\\n\\n'}, '46332325': {'pageid': 46332325, 'ns': 0, 'title': 'Python', 'index': 1, 'extract': '<p><b>Python</b> may refer to:\\n</p>'}, '53672527': {'pageid': 53672527, 'ns': 0, 'title': 'Python (codename)', 'index': 5, 'extract': '<p class=\"mw-empty-elt\">\\n</p>\\n\\n<p><b>Python</b> was a Cold War contingency plan of the British Government for the continuity of government in the event of nuclear war.\\n</p>'}, '317752': {'pageid': 317752, 'ns': 0, 'title': 'Python (missile)', 'index': 9, 'extract': '<p>The Rafael <b>Python</b> is a family of air-to-air missiles (AAMs) built by the Israeli weapons manufacturer Rafael Advanced Defense Systems, formerly RAFAEL Armament Development Authority. Originally starting with the <i>Shafrir</i> (Hebrew: <span lang=\"he\" dir=\"rtl\">שפריר</span>, loosely translated as a dome, or a protective cloak – the Israeli military considers itself mostly defensive, but also similar sounding to Dragonfly, a male form of inflection for Damselfly (שפירית)) series, the <i>Shafrir-1</i> missile was developed in 1959, followed by the <i>Shafrir-2</i> in early 1970s. Subsequently, the missiles were given the western name of \"<i>Python</i>\" by the parent company for export purposes, starting with the <i>Python-3</i> in 1978. Since then, it has been further developed and evolved into the <i>Python-4</i>, <i>Python-5</i>, <i>Derby</i> and also, the SPYDER, an advanced ground-based air-defence system. Currently, the missiles are in service with the armed forces of over fifteen countries from around the world.\\n</p>'}, '23862': {'pageid': 23862, 'ns': 0, 'title': 'Python (programming language)', 'index': 2, 'extract': '<p class=\"mw-empty-elt\">\\n\\n</p>\\n<p><b>Python</b> is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.</p><p>Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.</p><p>Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python\\xa00.9.0. Python\\xa02.0 was released in 2000. Python\\xa03.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python\\xa02.7.18, released in 2020, was the last release of Python\\xa02.</p><p>Python consistently ranks as one of the most popular programming languages.</p>'}, '88595': {'pageid': 88595, 'ns': 0, 'title': 'Reticulated python', 'index': 7, 'extract': '<p class=\"mw-empty-elt\">\\n</p>\\n<p>The <b>reticulated python</b> (<i><b>Malayopython reticulatus</b></i>) is a python species native to South and Southeast Asia. It is the world\\'s longest snake, and the third heaviest after the green anaconda and Burmese python. It is listed as least concern on the IUCN Red List because of its wide distribution. In several countries in its range, it is hunted for its skin, for use in traditional medicine, and for sale as pets. Due to this, reticulated pythons are one of the most economically important reptiles worldwide.</p><p>It is an excellent swimmer, has been reported far out at sea, and has colonized many small islands within its range.\\n</p><p>Like all pythons, it is a non-venomous constrictor. In very rare cases, adult humans have been killed (and in at least two reported cases, eaten) by reticulated pythons.</p>'}, '24193838': {'pageid': 24193838, 'ns': 0, 'title': 'Setuptools', 'index': 8, 'extract': '<p><b>setuptools</b> is a package development process library designed to facilitate packaging Python projects by enhancing the Python standard library <span>distutils</span> (distribution utilities). It includes:\\n</p>\\n<ul><li>Python package and module definitions</li>\\n<li>Distribution package metadata</li>\\n<li>Test hooks</li>\\n<li>Project installation</li>\\n<li>Platform-specific details</li>\\n<li>Python 3 support</li></ul>\\n\\n'}}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "query = 'Zara (retailer)'\n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "            'action':'query',\n",
    "            'format':'json',\n",
    "            'generator': \"search\",\n",
    "            'utf8':1,\n",
    "            'gsrsearch': subject,\n",
    "            'prop': 'extracts',\n",
    "            'exintro': True,\n",
    "        }\n",
    "\n",
    "data = requests.get(url, params=params).json() \n",
    "print(data)\n",
    "# for i in data['query']['search']:\n",
    "#     print(i['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ball python (Python regius), also called the royal python, is a python species native to West and Central Africa, where it lives in grasslands, shrublands and open forests. This nonvenomous constrictor is the smallest of the African pythons, growing to a maximum length of 182 cm (72 in). The name \"ball python\" refers to its tendency to curl into a ball when stressed or frightened.\n",
      "\n",
      "\n",
      "{'pageid': 271890, 'ns': 0, 'title': 'Ball python', 'index': 5, 'extract': 'The ball python (Python regius), also called the royal python, is a python species native to West and Central Africa, where it lives in grasslands, shrublands and open forests. This nonvenomous constrictor is the smallest of the African pythons, growing to a maximum length of 182 cm (72 in). The name \"ball python\" refers to its tendency to curl into a ball when stressed or frightened.\\n\\n'}\n",
      "{'pageid': 819149, 'ns': 0, 'title': 'Burmese python', 'index': 6}\n",
      "{'pageid': 639888, 'ns': 0, 'title': 'Colt Python', 'index': 10}\n",
      "{'pageid': 18942, 'ns': 0, 'title': 'Monty Python', 'index': 3}\n",
      "{'pageid': 46332325, 'ns': 0, 'title': 'Python', 'index': 1}\n",
      "{'pageid': 53672527, 'ns': 0, 'title': 'Python (codename)', 'index': 4}\n",
      "{'pageid': 317752, 'ns': 0, 'title': 'Python (missile)', 'index': 9}\n",
      "{'pageid': 23862, 'ns': 0, 'title': 'Python (programming language)', 'index': 2}\n",
      "{'pageid': 88595, 'ns': 0, 'title': 'Reticulated python', 'index': 7}\n",
      "{'pageid': 24193838, 'ns': 0, 'title': 'Setuptools', 'index': 8}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "subject = 'Python'\n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "        'origin':'*',\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'prop': 'extracts',\n",
    "        'exintro': True,\n",
    "        'explaintext': True,\n",
    "        'exlimit': 1,\n",
    "        \"redirects\": 1,\n",
    "        'generator': \"search\",\n",
    "        'gsrsearch': subject,\n",
    "    }\n",
    " \n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "print(list(data['query']['pages'].values())[0]['extract'])\n",
    "for i in data['query']['pages'].values():\n",
    "    print(i)\n",
    "    #print('Titulo:',i['title'],':\\n', i['extract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debian releases do not follow a fixed schedule. Recent releases have been made roughly biennially by the Debian Project. The most recent version of Debian is Debian version 12, codename \"Bookworm\". The next up and coming release of Debian is Debian 13, codename \"Trixie\".Debian always has at least three active branches at any time: \"stable\", \"testing\" and \"unstable\". The stable branch is considered the primary release and what most people refer to when talking about Debian. The testing branch contains packages that have been imported from unstable. Testing has significantly more up-to-date packages than stable and is frozen some time before a release to become the next version of Debian. The unstable release (also known as Sid) is the branch where active development takes place. It is the most volatile version of Debian.\n",
      "When the Debian stable branch is replaced with a newer release, the current stable becomes an \"oldstable\" release. When the Debian stable branch is replaced again, the oldstable release becomes the \"oldoldstable\" release. Oldoldstable is eventually moved to the archived releases repository.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject = 'Debian version history'\n",
    "url = 'https://en.wikipedia.org/w/api.php'\n",
    "params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'titles': subject,\n",
    "        'prop': 'extracts',\n",
    "        'exintro': True,\n",
    "        'explaintext': True,\n",
    "    }\n",
    " \n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    " \n",
    "page = next(iter(data['query']['pages'].values()))\n",
    "print(page['extract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia \n",
    "import time\n",
    "def wikipedia_info(subject: str) -> str:\n",
    "    time.sleep(50)\n",
    "    url = 'https://en.wikipedia.org/w/api.php'\n",
    "    params = {\n",
    "            'origin':'*',\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'prop': 'extracts',\n",
    "            'exintro': True,\n",
    "            'explaintext': True,\n",
    "            \"exlimit\": 1, \n",
    "            'generator': \"search\",\n",
    "            'gsrsearch': subject,\n",
    "            'gsrwhat':'text',\n",
    "            'gsrsort': 'relevance'\n",
    "        }\n",
    "    data = requests.get(url, params=params).json() \n",
    "\n",
    "    if \"query\" in data:\n",
    "        if len(data['query']['pages'])>1:\n",
    "            warnings = '**WARNING - need to check veracity**'\n",
    "            summary = warnings + list(data['query']['pages'].values())[0]['extract']\n",
    "            return summary\n",
    "        else:\n",
    "            params = {\n",
    "                    'action': 'query',\n",
    "                    'format': 'json',\n",
    "                    'titles': subject,\n",
    "                    'prop': 'extracts',\n",
    "                    'exintro': True,\n",
    "                    'explaintext': True,\n",
    "                }\n",
    "            \n",
    "            data = requests.get(url, params=params).json()            \n",
    "            page = next(iter(data['query']['pages'].values()))\n",
    "            return page['extract']\n",
    "    else: \n",
    "        if wikipedia.suggest(subject) is not None:\n",
    "            subject_suggested = wikipedia.suggest(subject)\n",
    "            return wikipedia_info(subject_suggested)\n",
    "        else: \n",
    "            return 'No match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for company_name in df['Company name']:\n",
    "    result = wikipedia_info(company_name)\n",
    "    result_dict[company_name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import logging\n",
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.level = logging.INFO\n",
    "\n",
    "\n",
    "URL = 'https://en.wikipedia.org/w/api.php'\n",
    "\n",
    "search_list_params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'prop': 'extracts',\n",
    "        'exintro': True,\n",
    "        'explaintext': True,\n",
    "        \"exlimit\": 1, \n",
    "        'generator': \"search\",\n",
    "        'gsrsearch': 'subject',\n",
    "}\n",
    "search_item_params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'titles': subject,\n",
    "        'prop': 'extracts',\n",
    "        'exintro': True,\n",
    "        'explaintext': True,\n",
    "}\n",
    "\n",
    "def wikipedia_info(subject: str):\n",
    "    time.sleep(10)\n",
    "    data = request_with_cooloff(url=URL, params=search_list_params)\n",
    "\n",
    "    if \"query\" in data:\n",
    "        if len(data['query']['pages'])>1:\n",
    "            warnings = '**WARNING - need to check veracity**'\n",
    "            summary = warnings + '\\n' + list(data['query']['pages'].values())[0]['extract']\n",
    "            return summary\n",
    "        else:\n",
    "            warnings = '**NO WARNING - just one item left**'\n",
    "            data = request_with_cooloff(url=URL, params=search_item_params)         \n",
    "            page = next(iter(data['query']['pages'].values()))\n",
    "            return page['extract']\n",
    "    else: \n",
    "        if wikipedia.suggest(subject) is not None:\n",
    "            subject_suggested = wikipedia.suggest(subject)\n",
    "            return wikipedia_info(subject_suggested)\n",
    "        else: \n",
    "            return 'No subject found in Wiki API'\n",
    "\n",
    "def _request_with_cooloff(\n",
    "    url: str, params: Dict[str, any], num_attempts: int, payload: Dict[str, any] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Call the url using requests. If the endpoint returns an error wait a cooloff\n",
    "    period and try again, doubling the period each attempt up to a max num_attempts.\n",
    "    \"\"\"\n",
    "    cooloff = 1\n",
    "    for call_count in range(num_attempts):\n",
    "        try:\n",
    "            response = requests.get(url,params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "        # If we're overloading the endpoint it may refuse a connection\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            logger.info(\"API refused the connection\")\n",
    "            logger.warning(e)\n",
    "            if call_count != (num_attempts - 1):\n",
    "                time.sleep(cooloff)\n",
    "                cooloff *= 2\n",
    "                call_count += 1\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # Catch non 200 return codes on the HTTP header\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            logger.warning(e)\n",
    "            if response.status_code == 404:\n",
    "                raise\n",
    "\n",
    "            logger.info(f\"API return code {response.status_code} cooloff at {cooloff}\")\n",
    "            if call_count != (num_attempts - 1):\n",
    "                time.sleep(cooloff)\n",
    "                cooloff *= 2\n",
    "                call_count += 1\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # We got through the loop without error so we've received a valid response\n",
    "        return response\n",
    "\n",
    "def request_with_cooloff(\n",
    "    url: str,\n",
    "    params: Dict[str, any],\n",
    "    num_attempts: int = 10,\n",
    "):\n",
    "    return json.loads(\n",
    "        _request_with_cooloff(\n",
    "            url,\n",
    "            params,\n",
    "            num_attempts\n",
    "        ).content.decode(\"utf-8\")\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    result_dict = {}\n",
    "    for company_name in df['Company name']:\n",
    "        result = wikipedia_info(company_name)\n",
    "        result_dict[company_name] = result\n",
    "    return result_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
